{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "\n",
    "from oracles import LogReg\n",
    "from methods import Standard_Newton, Newton_Star\n",
    "from methods import NL1\n",
    "from methods import DINGO, Gradient_Descent\n",
    "from methods import diana, adiana\n",
    "from methods import FedNL, FedNL_CR, FedNL_LS\n",
    "from methods import Newton_Zero\n",
    "from methods import FedNL_BC, FedNL_PP\n",
    "from methods import Artemis, DORE\n",
    "\n",
    "from utils import read_data, generate_synthetic\n",
    "from utils import loss_logistic, grad, random_k, positive_part\n",
    "from utils import default_dataset_parameters\n",
    "from utils import topK_vectors, biased_rounding, randomK_vectors\n",
    "from utils import Low_Rank, PowerSgdCompression, TopK\n",
    "from utils import pos_projection, semidef_projection\n",
    "from utils import random_spars_matrix, rand_dith\n",
    "\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'a1a'\n",
    "dataset_path = './Datasets/{}.txt'.format(data_name)\n",
    "\n",
    "\n",
    "# regularization parameter\n",
    "lmb = 1e-3\n",
    "\n",
    "# number of nodes, size of local data, and dimension of the problem\n",
    "# according to the paper\n",
    "N = default_dataset_parameters[data_name]['N']# size of the whole data set\n",
    "n = default_dataset_parameters[data_name]['n']# number of nodes\n",
    "m = default_dataset_parameters[data_name]['m']# size of local data set\n",
    "d = default_dataset_parameters[data_name]['d']# dimension of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = read_data(dataset_path=dataset_path, \n",
    "                 N=N, n=n, m=m, d=d, lmb=lmb,\n",
    "                labels=['+1', '-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the problem \n",
    "logreg = LogReg(A=A, b=b, reg_coef=lmb, n=n, m=m)\n",
    "\n",
    "# find the solution using Newton's method starting from zeros for 20 iterations\n",
    "Newton = Standard_Newton(logreg)\n",
    "Newton.find_optimum(x0=np.zeros(d), n_steps=20,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimum and optimal function value\n",
    "x_opt = logreg.get_optimum()\n",
    "f_opt = logreg.function_value(x_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-approval",
   "metadata": {},
   "source": [
    "# Newton-Zero\n",
    "\n",
    "***input:***\n",
    "- `x` - initial model weightsn\n",
    "- `init_cost` - if True, then the communication cost of initalization is inclued\n",
    "- `line_search` - if True, then the method uses backtracking line search procedure\n",
    "- `gamma` - parameter of line search procedure\n",
    "- `c` - parameter of line search procedure\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `max_iter` - maximum number of iterations\n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server\n",
    "- `iterates` - numpy array containing distances from current point to the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial point \n",
    "x = x_opt + np.ones(d)*0.1\n",
    "\n",
    "# define the method\n",
    "n0 = Newton_Zero(logreg)\n",
    "\n",
    "# run the method\n",
    "fv, bi, it = n0.method(x=x, init_cost=False,\n",
    "                      line_search=False, gamma=0.5, c=0.5,\n",
    "                      tol=1e-15, max_iter=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-bridge",
   "metadata": {},
   "source": [
    "# FedNL\n",
    "\n",
    "the example how to run FedNL method. It has the following parameters:\n",
    "\n",
    "***input:***\n",
    "- `x` - initial point\n",
    "- `hes_comp_param` - parameter of local Hessian compression operator\n",
    "- `hes_comp_name` - name of compression operator for Hessians\n",
    "  - `LowRank` (Rank-R) compression operator (`upd_rule` 1 or 2)\n",
    "  - `TopK` (Top-K) compression operator (`upd_rule` 1 or 2)\n",
    "  - `PowerSGD` compression operator (`upd_rule` 1 or 2)\n",
    "  - `RandomK` (Rand-K) compression operator (`upd_rule` 3)\n",
    "- `init` - if zero, then $\\mathbf{H}^0_i = \\mathbf{0}$, otherwise $\\mathbf{H}^0_i = \\nabla^2 f_i(x^0)$\n",
    "- `init_cost` - if True, then the communication cost on initialization is included\n",
    "- `option` \n",
    "  - if 1, then the method uses Option 1 of FedNL \n",
    "  - if 2, then the method uses Option 2 of FedNL\n",
    "- `upd_rule` \n",
    "  - if 1, then method requires Biased compressor and uses stepsize $\\alpha=1-\\sqrt{1-\\delta}$\n",
    "  - if 2, then method requires Biased compressor and uses stepsize $\\alpha=1$\n",
    "  - if 3, then methods requires Unbiased compressor and uses stepsize $\\alpha=\\frac{1}{\\omega+1}$\n",
    "- `lr` - learning rate if the user wants to use PowerSGD where stepsize can be chosen\n",
    "- `max_iter` - maximum number of iterations\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `bits_compute` \n",
    "  - if OneSided, then bits are computed in upside direction only\n",
    "  - if TwoSided, then bits are computed in both directions: upside and backside\n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `iterates` - numpy array containing distances from current point to the solution\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial point\n",
    "np.random.seed(1)\n",
    "x = x_opt + np.ones(d)*0.15\n",
    "\n",
    "# define the method\n",
    "fednl = FedNL(logreg)\n",
    "\n",
    "# run the method\n",
    "fv, bi, it = fednl.method(x=x,hes_comp_name='LowRank', hes_comp_param=1, \n",
    "                          init='nonzero', init_cost=True,\n",
    "                          option=1, upd_rule=2,\n",
    "                          lr=None, max_iter=1000, tol=1e-15,\n",
    "                          bits_compute='OneSided', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-impression",
   "metadata": {},
   "source": [
    "# FedNL-LS\n",
    "\n",
    "the example how to run FedNL method. It has the following parameters:\n",
    "\n",
    "***input:***\n",
    "- `x` - initial point\n",
    "- `hes_comp_param` - parameter of local Hessian compression operator. It can be\n",
    "- `hes_comp_name` - name of compression operator for Hessians\n",
    "  - `LowRank` (Rank-R) compression operator (`upd_rule` 1 or 2)\n",
    "  - `TopK` (Top-K) compression operator (`upd_rule` 1 or 2)\n",
    "  - `PowerSGD` compression operator (`upd_rule` 1 or 2)\n",
    "  - `RandomK` (Rand-K) compression operator (`upd_rule` 3)\n",
    "- `init` - if zero, then $\\mathbf{H}^0_i = \\mathbf{0}$, otherwise $\\mathbf{H}^0_i = \\nabla^2 f_i(x^0)$\n",
    "- `init_cost` - if True, then the communication cost on initialization is included\n",
    "- `max_iter` - maximum number of iterations\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `bits_compute` \n",
    "  - if OneSided, then bits are computed in upside direction only\n",
    "  - if TwoSided, then bits are computed in both directions: upside and backside\n",
    "- `upd_rule` \n",
    "  - if 1, then method requires Biased compressor and uses stepsize $\\alpha=1-\\sqrt{1-\\delta}$\n",
    "  - if 2, then method requires Biased compressor and uses stepsize $\\alpha=1$\n",
    "  - if 3, then methods requires Unbiased compressor and uses stepsize $\\alpha=\\frac{1}{\\omega+1}$\n",
    "- `gamma` - parameter of line search procedure\n",
    "- `c` - parameter of line search procedure\n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `iterates` - numpy array containing distances from current point to the solution\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial point\n",
    "x  = x_opt + np.ones(d)*2\n",
    "\n",
    "# define method\n",
    "fednl_ls = FedNL_LS(logreg)\n",
    "\n",
    "# run the method\n",
    "\n",
    "fv, bi, it = fednl_ls.method(x=x, hes_comp_param=d, hes_comp_name='TopK', \n",
    "                             init='nonzero', init_cost=False, \n",
    "                             max_iter=20, tol=1e-15, \n",
    "                             bits_compute='OneSided', upd_rule=1,\n",
    "                             gamma=0.5, c=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-snake",
   "metadata": {},
   "source": [
    "# FedNL-CR\n",
    "\n",
    "***input:***\n",
    "- `x` - initial point\n",
    "- `hes_comp_param` - parameter of local Hessian compression operator\n",
    "- `hes_comp_name` - name of compression operator for Hessians\n",
    "  - `LowRank` (Rank-R) compression operator (`upd_rule` 1 or 2)\n",
    "  - `TopK` (Top-K) compression operator (`upd_rule` 1 or 2)\n",
    "  - `PowerSGD` compression operator (`upd_rule` 1 or 2)\n",
    "  - `RandomK` (Rand-K) compression operator (`upd_rule` 3)\n",
    "- `init` - if zero, then $\\mathbf{H}^0_i = \\mathbf{0}$, otherwise $\\mathbf{H}^0_i = \\nabla^2 f_i(x^0)$\n",
    "- `init_cost` - if True, then the communication cost on initialization is included\n",
    "- `upd_rule` \n",
    "  - if 1, then method requires Biased compressor and uses stepsize $\\alpha=1-\\sqrt{1-\\delta}$\n",
    "  - if 2, then method requires Biased compressor and uses stepsize $\\alpha=1$\n",
    "  - if 3, then methods requires Unbiased compressor and uses stepsize $\\alpha=\\frac{1}{\\omega+1}$\n",
    "- `max_iter` - maximum number of iterations\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `bits_compute` \n",
    "  - if OneSided, then bits are computed in upside direction only\n",
    "  - if TwoSided, then bits are computed in both directions: upside and backside\n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `iterates` - numpy array containing distances from current point to the solution\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial point\n",
    "x  = x_opt + np.ones(d)*2\n",
    "\n",
    "# define method\n",
    "fednl_cr = FedNL_CR(logreg)\n",
    "\n",
    "# run the method\n",
    "\n",
    "fv, bi, it = fednl_cr.method(x=x, hes_comp_param=1, hes_comp_name='LowRank', \n",
    "                             init='zero', init_cost=False, \n",
    "                             upd_rule=3, max_iter=20, tol=1e-15, \n",
    "                             bits_compute='OneSided', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-argument",
   "metadata": {},
   "source": [
    "# FedNL-BC\n",
    "\n",
    "***input:***\n",
    "- `x` - initial point\n",
    "- `hes_comp_param` - parameter of local Hessian compression operator\n",
    "- `hes_comp_name` - name of compression operator for Hessians\n",
    "  - `LowRank` (Rank-R) compression operator (`upd_rule` 1 or 2)\n",
    "  - `TopK` (Top-K) compression operator (`upd_rule` 1 or 2)\n",
    "  - `PowerSGD` compression operator (`upd_rule` 1 or 2)\n",
    "  - `RandomK` (Rand-K) compression operator (`upd_rule` 3)\n",
    "- `iter_comp_param` - parameter of compression operator applied to models\n",
    "- `iter_comp_name` - name of compression operator for models\n",
    "  - `TopK` (Top-K) compression operator (`iter_upd_rule` 1 or 2)\n",
    "  - `Rounding` compression operator (`iter_upd_rule` 1 or 2)\n",
    "  - `RandomK` (Rand-K) compressio operator (`iter_upd_rule` 3)\n",
    "- `init` - if zero, then $\\mathbf{H}^0_i = \\mathbf{0}$, otherwise $\\mathbf{H}^0_i = \\nabla^2 f_i(x^0)$\n",
    "- `init_cost` - if True, then the communication cost on initialization is included\n",
    "- `upd_rule` \n",
    "  - if 1, then method requires Biased compressor and uses stepsize $\\alpha=1-\\sqrt{1-\\delta}$\n",
    "  - if 2, then method requires Biased compressor and uses stepsize $\\alpha=1$\n",
    "  - if 3, then methods requires Unbiased compressor and uses stepsize $\\alpha=\\frac{1}{\\omega+1}$\n",
    "- `iter_upd_rule` \n",
    "  - if 1, then method requires Biased compressor and uses stepsize $\\eta=1-\\sqrt{1-\\delta_M}$\n",
    "  - if 2, then method requires Biased compressor and uses stepsize $\\eta=1$\n",
    "  - if 3, then methods requires Unbiased compressor and uses stepsize $\\eta=\\frac{1}{\\omega_M+1}$\n",
    "- `option` \n",
    "  - if 1, then the method uses Option 1 of FedNL-BC \n",
    "  - if 2, then the method uses Option 2 of FedNL-BC\n",
    "- `max_iter` - maximum number of iterations\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `bits_compute` \n",
    "  - if OneSided, then bits are computed in upside direction only\n",
    "  - if TwoSided, then bits are computed in both directions: upside and backside\n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `iterates` - numpy array containing distances from current point to the solution\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial point\n",
    "np.random.seed(1)\n",
    "x = x_opt + np.ones(d)*0.1\n",
    "\n",
    "# define method\n",
    "fednl_bc = FedNL_BC(logreg)\n",
    "\n",
    "# run the method\n",
    "p = 0.5\n",
    "fv, bi, it = fednl_bc.method(x=x, hes_comp_param=int(p*d), hes_comp_name='TopK', \n",
    "                             p=0.5, iter_comp_param=int(p*d), iter_comp_name='TopK',\n",
    "                             init='nonzero', init_cost=False, \n",
    "                             upd_rule=2, iter_upd_rule=1,\n",
    "                             max_iter=20, tol=1e-15, \n",
    "                             verbose=True, option=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-calendar",
   "metadata": {},
   "source": [
    "# FedNL-PP\n",
    "\n",
    "***input:*** \n",
    "- `x` - initial point\n",
    "- `tau` - number of active nodes\n",
    "- `hes_comp_param` - parameter of local Hessian compression operator\n",
    "- `hes_comp_name` - name of compression operator for Hessians\n",
    "  - `LowRank` (Rank-R) compression operator (`upd_rule` 1 or 2)\n",
    "  - `TopK` (Top-K) compression operator (`upd_rule` 1 or 2)\n",
    "  - `PowerSGD` compression operator (`upd_rule` 1 or 2)\n",
    "  - `RandomK` (Rand-K) compression operator (`upd_rule` 3)\n",
    "- `init` - if zero, then $\\mathbf{H}^0_i = \\mathbf{0}$, otherwise $\\mathbf{H}^0_i = \\nabla^2 f_i(x^0)$\n",
    "- `init_cost` - if True, then the communication cost on initialization is included  \n",
    "- `upd_rule` \n",
    "  - if 1, then method requires Biased compressor and uses stepsize alpha=1-\\sqrt{1-delta}\n",
    "  - if 2, then method requires Biased compressor and uses stepsize alpha=1\n",
    "  - if 3, then methods requires Unbiased compressor and uses stepsize alpha=1/(omega+1)\n",
    "- `max_iter` - maximum number of iterations\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `bits_compute`\n",
    "  - if OneSided, then bits are computed in upside direction only\n",
    "  - if TwoSided, then bits are computed in both directions: upside and backside\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `iterates` - numpy array containing distances from current point to the solution\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial point\n",
    "np.random.seed(1)\n",
    "x = x_opt + np.ones(d)*0.1\n",
    "\n",
    "# define method\n",
    "fednl_pp = FedNL_PP(logreg)\n",
    "\n",
    "# run the method\n",
    "p = 0.5\n",
    "fv, bi, it = fednl_pp.method(x=x, tau=int(0.5*n),\n",
    "                             hes_comp_param=1, hes_comp_name='LowRank',\n",
    "                             init='zero', init_cost=False, \n",
    "                             upd_rule=2, max_iter=20, tol=1e-15, \n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-graphics",
   "metadata": {},
   "source": [
    "# Gradient descent\n",
    "\n",
    "***input:***\n",
    "- `x` - initial model weightsn\n",
    "- `line_search` - if True, then the method uses backtracking line search procedure\n",
    "- `gamma` - parameter of line search procedure\n",
    "- `c` - parameter of line search procedure\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `max_iter` - maximum number of iterations\n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server\n",
    "- `iterates` - numpy array containing distances from current point to the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial point\n",
    "x = x_opt + np.ones(d)*2\n",
    "\n",
    "# define method\n",
    "gd = Gradient_Descent(logreg)\n",
    "\n",
    "# run the method\n",
    "fv, bi, it = gd.method(x=x, line_search=True,\n",
    "                       gamma=0.5, c=0.5,\n",
    "                       tol=1e-15, max_iter=20,\n",
    "                       verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-luxury",
   "metadata": {},
   "source": [
    "# DINGO\n",
    "\n",
    "***input:***\n",
    "- `x` - initial point\n",
    "- `max_iter` - maximum iterations of the method\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `phi`, `theta`, `rho` - parameters of DINGO\n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial point\n",
    "x = x_opt + np.ones(d)*0.1\n",
    "\n",
    "# define method\n",
    "dingo = DINGO(logreg)\n",
    "\n",
    "# run the method\n",
    "fv, bi = dingo.method(x=x, phi=1e-6, theta=1e-4, \n",
    "                      rho=1e-4, tol=1e-15, \n",
    "                      max_iter=20, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-integral",
   "metadata": {},
   "source": [
    "# ADIANA and DIANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta, alpha, theta_1, theta_2, gamma are parameters of ADIANA \n",
    "class args(EasyDict):\n",
    "    def __init__(self, data_name, T, node, L, lamda, eta=0.05,\n",
    "                 alpha=0.5, theta_1=0.25, theta_2=0.5, gamma=0.5,\n",
    "                 beta=0.95,\n",
    "                 prob=1,\n",
    "                 comp_method='no_comp',\n",
    "                 r=None, s=None, s_level=10):\n",
    "        super().__init__()\n",
    "        self.data_name = data_name\n",
    "        # T - maximum number of iterations\n",
    "        self.T = T\n",
    "        # number of nodes\n",
    "        self.node = node\n",
    "        # parameters of ADIANA\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "        self.theta_1 = theta_1\n",
    "        self.theta_2 = theta_2\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.prob = prob\n",
    "        # Lipshitz constant of gradients\n",
    "        self.L = L\n",
    "        # regularization parameter\n",
    "        self.lamda = lamda\n",
    "        # name of compression operator\n",
    "        self.comp_method = comp_method\n",
    "        # parameter of random sparsification\n",
    "        # compression operator\n",
    "        self.r = r\n",
    "        # parameter of randim dithering\n",
    "        # compression operator\n",
    "        self.s = s\n",
    "    \n",
    "# find Lipshitz constant of gradients\n",
    "H = np.dot(A.T,A)/N\n",
    "temp = np.linalg.eigvalsh(H)\n",
    "L = np.abs(temp[-1])/4\n",
    "\n",
    "# define maximum number of iterations\n",
    "max_iter = 200\n",
    "\n",
    "# set class containing all parameters\n",
    "arg = args(data_name, max_iter, n, L, lmb)\n",
    "\n",
    "# set parameters of compression operators\n",
    "arg.r = d/4\n",
    "arg.s = np.sqrt(d)\n",
    "\n",
    "# set compression operator\n",
    "comp_methods = [\n",
    "     'rand_dithering'\n",
    "]\n",
    "\n",
    "# put compression operator to arg's\n",
    "arg.comp_method = comp_methods[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ADIANA\n",
    "loss_adiana, com_bits_adiana = adiana(A, b, x, arg, f_opt=f_opt, tol=1e-15)\n",
    "\n",
    "# method prints function values each 1000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ADIANA\n",
    "\n",
    "loss_diana, com_bits_diana = diana(A, b, x, arg, f_opt=f_opt, tol=1e-15)\n",
    "# method prints function values each 1000 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-heading",
   "metadata": {},
   "source": [
    "# Artemis \n",
    "\n",
    "***input:***\n",
    "- `x` - initial model weights\n",
    "- `tau` - number of active nodes\n",
    "- `compression` \n",
    "  - if OneSided, then random dithering is applied only on uplink direction\n",
    "  - if TwoSided, then random dithering is applied both on uplink and downlink directions\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `max_iter` - maximum number of steps of the method \n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `iterates- - numpy array containing distances from current point to the solution\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "artemis = Artemis(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv, bi, it = artemis.method(x=x_opt+np.ones(d)*0.1, tau=n, max_iter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-conflict",
   "metadata": {},
   "source": [
    "# DORE\n",
    "\n",
    "***input:***\n",
    "- `x` - initial model weights\n",
    "- `tol` - desired tolerance of the solution\n",
    "- `max_iter` - maximum number of steps of the method \n",
    "- `verbose` - if True, then function values in each iteration are printed\n",
    "\n",
    "***return:***\n",
    "- `func_value` - numpy array containing function value in each iteration of the method\n",
    "- `iterates` - numpy array containing distances from current point to the solution\n",
    "- `bits` - numpy array containing transmitted bits by one node to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "dore = DORE(logreg)\n",
    "\n",
    "fv, bi, it = dore.method(x=x_opt+np.ones(d)*0.1, max_iter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-breast",
   "metadata": {},
   "source": [
    "# Synthetic data\n",
    "\n",
    "In our experiments we also generate synthetic data. This can be done using the function `generate_synthetic`. It has the following parameters:\n",
    "\n",
    "***input:***\n",
    "- `alpha`, `beta` - parameters of data\n",
    "- `iid`\n",
    "  - if 1, then the data distribution over nodes is iid\n",
    "  - if 0, then the data distribution over nodes is non-iid\n",
    "- `d` - dimension of the problem\n",
    "- `n` - number of nodes\n",
    "- `m` - size of local data\n",
    "    \n",
    "***output:***\n",
    "- numpy arrays A (features) and b (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-collins",
   "metadata": {},
   "source": [
    "Example of IID data generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = generate_synthetic(alpha=0.5, beta=0.5, iid=1, d=d, n=n, m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-compiler",
   "metadata": {},
   "source": [
    "Example of non-IID data generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = generate_synthetic(alpha=0.5, beta=0.5, iid=0, d=d, n=n, m=m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
